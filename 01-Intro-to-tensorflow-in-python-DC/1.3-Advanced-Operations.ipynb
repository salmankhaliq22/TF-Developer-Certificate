{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b6ee1c-4989-4fe0-a04d-908bdbdd2f29",
   "metadata": {},
   "source": [
    "# Tensorflow Developer Certificate Preparation\n",
    "___\n",
    "## Introduction to Tensorflow in Python - DataCamp - ML-Scientist-Career-Track - by Isaiah Hull\n",
    "___\n",
    "## Chapter 1.3- Advanced Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64804e06-bcef-4e8a-8159-b23c78a5aa12",
   "metadata": {},
   "source": [
    "### 1. Advanced Operations\n",
    "In this notebook, we will cover a selection of advanced operations. Some will be used frequently in later notebooks. Others will help you to gain intuition about complex machine learning routines.\n",
    "\n",
    "### 2. Overview of advanced operations\n",
    "- We have already covered basic operations in TensorFlow, including ``add()``, ``multiply()``, ``matmul()``, and ``reduce_sum()``. \n",
    "- In this notebook, we will move on to more advanced operations, including ``gradient()``, ``reshape()``, and ``random()``.\n",
    "\n",
    "### 3. Overview of advanced operations\n",
    "\n",
    "| Operation| Use |\n",
    "|-|-|\n",
    "|``gradient()``|computes the slope of a function at a point.| \n",
    "|``reshape()``|changes the shape of a tensor.         |        \n",
    "|``random()``|generates a tensor out of randomly-drawn values.         |\n",
    "\n",
    "### 4. Finding the optimum\n",
    "- In many machine learning problems, you will need to find an optimum of a function.\n",
    "    - **Minimum:** Lowest value of a loss function\n",
    "    - **Maximum:** Highest value of objective function. \n",
    "- Fortunately, we can do this by using the ``gradient()`` operation, which tells us the slope of a function at a point.\n",
    "    - **Optimum:** Find a point where gradient = 0\n",
    "    - **Minimum:** Change in gradient > 0\n",
    "    - **Maximum:** Change in gradient < 0\n",
    "\n",
    "### 5. Calculating the gradient\n",
    "The plot shows the function $$y = x$$. Notice that the gradient--that is, the slope at a given point, is constant. If we increase x by 1 unit, y also increases by 1 unit.\n",
    "![Figure](./figures/1.3.1.PNG)\n",
    "\n",
    "### 6. Calculating the gradient\n",
    "This is not true if we instead consider the function $$y = x^2$$. When x is less than 0, y decreases when x increases. When x is greater than 0, y increases when x increases. Thus, the gradient is initially negative, but becomes positive for x larger than 0. This means that x equals 0 minimizes y.  \n",
    "![Figure](./figures/1.3.2.PNG)\n",
    "\n",
    "### 7. Gradients in TensorFlow\n",
    "Let's use TensorFlow to compute the gradient:  \n",
    "- We will start by defining a variable, x, which we initialize to minus one point zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab393ea-5a0d-4ae8-9c10-a1922959aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow \n",
    "import tensorflow as tf\n",
    "\n",
    "# Define x\n",
    "x = tf.Variable(-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaefe23d-53ea-4539-b6ec-237e7334de7e",
   "metadata": {},
   "source": [
    "- We will then define y to be x squared within an instance of gradient tape. \n",
    "- Note that we apply the watch method to an instance of gradient tape and then pass the variable x. \n",
    "- This will allow us to compute the rate of change of y with respect to x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556e6097-3487-4054-b8a4-be2948886e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y within instance of GradientTape\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y= tf.multiply(x,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f85c7b-a5cc-4c79-aeed-84c8b80289e7",
   "metadata": {},
   "source": [
    "- Next, we compute the gradient of y with respect to x using the tape instance of gradient tape. \n",
    "- Note that y is the first argument and x is the second. \n",
    "- As written, the operation computes the slope of y at a point. \n",
    "- Running the code and printing, we find that the slope is -2 at x equals -1, which means that y is initially decreasing in x, as we saw on the previous slide. \n",
    "- Much of the differentiation you do in deep learning models will be handled by high level APIs; however, gradient tape remains an invaluable tool for building advanced and custom models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f06b87-cd59-4508-9a10-abe6a26220c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the gradient of y at x = -1\n",
    "g = tape.gradient(y,x)\n",
    "print(g.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e17621c-a836-4ff4-b29a-31c13bb9ef96",
   "metadata": {},
   "source": [
    "### 8. Images as tensors\n",
    "- We'll next consider an operation that is particularly useful for image classification problems: ``reshaping()``.  \n",
    "![Figure](./figures/1.3.3.PNG)\n",
    "- The grayscale image shown has a natural representation as a matrix with values between 0 and 255. While some algorithms exploit this shape, others require you to reshape matrices into vectors before using them as inputs, as shown in the diagram.\n",
    "\n",
    "### 9. How to reshape a grayscale image\n",
    "- Now that you've seen how images can be represented as tensors, let's generate some input images and reshape them. \n",
    "- We will create a random grayscale image by drawing numbers from the set of integers between 0 and 255. \n",
    "- We will use these to populate a 2 by 2 matrix. \n",
    "- We can then reshape this into a 4 by 1 vector, as shown in the diagram.\n",
    "![Figure](./1.3.4.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec823893-9852-4d7c-936a-cf58fe30e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate grayscale image\n",
    "gray = tf.random.uniform([2,2], maxval = 255, dtype = 'int32')\n",
    "\n",
    "# Reshape grayscale image\n",
    "gray = tf.reshape(gray, [2*2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc5fab-0b84-485b-bc3e-61e735575441",
   "metadata": {},
   "source": [
    "### 10. How to reshape a color image\n",
    "- For color images, we will generate 3 such matrices to form a 2 by 2 by 3 tensor. \n",
    "- We could then reshape the image into a 4 by 3 tensor, as shown in the diagram.\n",
    "![Figure](./figures/1.3.5.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1489a78-a7ce-4b4f-9aa7-7d6ec77b06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate color image\n",
    "color = tf.random.uniform([2,2,3], maxval = 255, dtype = 'int32')\n",
    "\n",
    "# Reshape color image\n",
    "color = tf.reshape(color, [2*2, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
