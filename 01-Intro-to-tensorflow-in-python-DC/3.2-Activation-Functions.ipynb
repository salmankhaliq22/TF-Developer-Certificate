{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781205b9-fad5-47ed-9cca-e2eacbed3e87",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tensorflow Developer Certificate Preparation\n",
    "___\n",
    "## Introduction to Tensorflow in Python - DataCamp - ML-Scientist-Career-Track - by Isaiah Hull\n",
    "___\n",
    "## Chapter 3.2 - Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b661f-ba14-4c3a-a49a-f0db65128937",
   "metadata": {},
   "source": [
    "### 1. Activation functions\n",
    "In the previous notebook, we discussed dense layers. We also briefly introduced the concept of an activation function through the sigmoid function. We will now return to activation functions.\n",
    "\n",
    "### 2. What is an activation function?\n",
    "A typical hidden layer consists of two operations. \n",
    "- The **first** performs **matrix multiplication**, which is a ``linear operation``, and the **second** applies an **activation function**, which is ``nonlinear operation``.\n",
    "\n",
    "### 3. Why nonlinearities are important\n",
    "Consider a simple model using the credit card data. The features are borrower age and credit card bill amount. The target variable is default.\n",
    "![3.2.1](./figures/3.2.1.PNG)\n",
    "\n",
    "\n",
    "Let's say we create a scatterplot of age and bill amount.   \n",
    "![3.2.2](./figures/3.2.2.PNG)  \n",
    "\n",
    "We can see that bill amount usually increases early in life and decreases later in life. This suggests that a high bill for young and older borrowers may mean something different for default. If we want our model to capture this, it can't be linear. It must allow the impact of the bill amount to depend on the borrower's age. This is what an activation function does.\n",
    "\n",
    "### 4. A simple example\n",
    "Let's look at a simple example, where we assume that the weight on age is 1 and the weight on the bill amount is 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b27aef-eb50-4480-8717-70654e2aaf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define example borrower features\n",
    "young, old = 0.3, 0.6\n",
    "low_bill, high_bill = 0.1, 0.5\n",
    "\n",
    "# Apply matrix multiplication step for all  feature combination\n",
    "young_high = 1.0*young +2.0*high_bill\n",
    "young_low = 1.0*young + 2.0*low_bill\n",
    "old_high = 1.0*old + 2.0*high_bill\n",
    "old_low = 1.0*old + 2.0*low_bill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daddfd0-50f8-4663-aff5-8adf576ccbf4",
   "metadata": {},
   "source": [
    "- Note that ages are divided by 100 and the bill's amount is divided by 10000. We then perform the matrix multiplication step for all combinations of features: young with a high bill, young with a low bill, old with a high bill, and old with a low bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02227ec5-b5e6-4c04-913f-674e3c705a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Difference in default predictions for young\n",
    "print(young_high - young_low)\n",
    "\n",
    "# Difference in default predictions for old\n",
    "print(old_high - old_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4737f6-61a8-4d75-8971-e335db75bc88",
   "metadata": {},
   "source": [
    "- If we don't apply an activation function and we assume the bias is zero, we find that the impact of bill size on default does not depend on age. In both cases, we predict a value of 0 point 8. Note that our target is a binary variable that is equal to 1 when the borrower defaults; however, predictions will be real numbers between 0 and 1, where values over 0 point 5 will be treated as predicting default.\n",
    "\n",
    "- But what if we apply a sigmoid activation function? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba6a800-435e-4d27-813b-19d3b23336e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16337562\n",
      "0.14204395\n"
     ]
    }
   ],
   "source": [
    "# Difference in default predictions for young\n",
    "print(tf.keras.activations.sigmoid(young_high).numpy() - tf.keras.activations.sigmoid(young_low).numpy())\n",
    "\n",
    "# Difference in default predictions for old\n",
    "print(tf.keras.activations.sigmoid(old_high).numpy() - tf.keras.activations.sigmoid(old_low).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd937c-18f1-4cfd-bec4-e20d6a04265d",
   "metadata": {},
   "source": [
    "The impact of bill amount on default now depends on the borrower's age. In particular, we can see that the change in the predicted value for default is larger for young borrowers than it is for old borrowers.\n",
    "\n",
    "### 5. The activation functions\n",
    "In this notebook, we'll use the three most common activation functions: \n",
    "- sigmoid \n",
    "- relu\n",
    "- softmax. \n",
    "\n",
    "### 6. The sigmoid activation function\n",
    "- The sigmoid activation function is used primarily in the **output layer of binary classification problems**. \n",
    "- When we use the low-level approach, we'll pass the sum of the product of weights and inputs into ``tf.keras.activations.sigmoid()``\n",
    "- When we use the high-level approach, we'll simply pass ``sigmoid`` as a parameter to a keras dense layer.  \n",
    "![3.2.3](./figures/3.2.3.PNG)\n",
    "\n",
    "### 7. The relu activation function\n",
    "- We'll typically use the ``rectified linear unit`` or ``relu`` activation in ``all hidden layers`` **other than** the ``output layer``. \n",
    "- When we use the low-level approach, we'll pass the sum of the product of weights and inputs into ``tf.keras.activations.relu()``\n",
    "- When we use the high-level approach, we'll simply pass ``relu`` as a parameter to a keras dense layer.\n",
    "- This activation simply takes the maximum of the value passed to it and 0.  \n",
    "![3.2.4](./figures/3.2.4.PNG)\n",
    "\n",
    "### 8. The softmax activation function\n",
    "- Finally, the ``softmax activation function`` is used in the ``output layer`` in classification problems with ``more than two classes``. \n",
    "- The outputs from a softmax activation function can be interpreted as predicted class probabilities in multiclass classification problems.\n",
    "- When we use the low-level approach, we'll pass the sum of the product of weights and inputs into ``tf.keras.activations.softmax()``\n",
    "- When we use the high-level approach, we'll simply pass ``softmax`` as a parameter to a keras dense layer.\n",
    "\n",
    "### 9. Activation functions in neural networks\n",
    "- Let's wrap up by applying some activation functions in a neural network. \n",
    "- We'll do this using the high-level approach, starting with an input layer. \n",
    "- We'll pass this to our first dense layer, which has 16 output nodes and a relu activation. \n",
    "- Dense layer 2 then reduces the number of nodes from 16 to 8 and applies a sigmoid activation. \n",
    "- Finally, we apply a softmax activation function in the output layer, since there are more than 2 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23615599-093b-4701-ad5c-d0bf2937d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define input layer (borrower_features are not defined\n",
    "# inputs = tf.constant(borrower_features, tf.float32)\n",
    "\n",
    "# Define dense layer 1\n",
    "# dense1 = tf.keras.layers.Dense(16, activation = 'relu')(inputs)\n",
    "\n",
    "# Define dense layer 2\n",
    "# dense2 = tf.keras.layers.Dense(8, activation = 'sigmoid')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "# outputs = tf.keras.layers.Dense(4, activation = 'softmax')(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987cb9b4-810d-4f2d-b4cf-d50848e79425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
