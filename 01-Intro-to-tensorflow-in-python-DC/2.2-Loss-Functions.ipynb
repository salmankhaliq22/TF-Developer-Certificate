{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e94246-d213-4985-bda5-e333ffd95eaa",
   "metadata": {},
   "source": [
    "# Tensorflow Developer Certificate Preparation\n",
    "___\n",
    "## Introduction to Tensorflow in Python - DataCamp - ML-Scientist-Career-Track - by Isaiah Hull\n",
    "___\n",
    "## Chapter 2.2- Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a845cc-220f-4912-8c57-752a0120a27a",
   "metadata": {},
   "source": [
    "### 1. Introduction to loss functions\n",
    "- Loss functions play a fundamental role in machine learning. \n",
    "- We need loss functions to train models because they tell us how well our model explains the data. \n",
    "- Without this feedback, it is unclear how to adjust model parameters during the training process. \n",
    "- A high loss value indicates that the model fit is poor. \n",
    "- Typically, we train the model by selecting parameter values that minimize the loss function. \n",
    "- In some cases, we may want to maximize a function instead. \n",
    "- Fortunately, we can always place a minus sign before the function we want to maximize and instead minimize it. \n",
    "- For this reason, we will always talk about loss functions and minimization.\n",
    "\n",
    "### 2. Common loss functions in TensorFlow\n",
    "- While it is possible to define a custom loss function, this is typically not necessary, since many common options are available in TensorFlow. \n",
    "- Typical choices for training linear models include the ``mean_squared_error`` loss, the ``mean_absolute_error`` loss, and the ``Huber Error``. \n",
    "- All of these are accessible from ``tf.keras.losses``\n",
    "    - ``tf.keras.losses.mse()``\n",
    "    - ``tf.kears.losses.mae()``\n",
    "    - ``tf.keras.losses.Hubber()``\n",
    "    \n",
    "\n",
    "### 3. Why do we care about loss functions?\n",
    "Here, we plot the MSE, MAE, and Huber loss for error values between minus two and two. \n",
    "- Note that the MSE strongly penalizes outliers and has high sensitivity near the minimum. \n",
    "- The MAE scales linearly with the size of the error and has low sensitivity near the minimum. \n",
    "- And the Huber loss is similar to the MSE near zero and similar to the MAE away from zero. \n",
    "- **For greater sensitivity near the minimum, you will want to use the MSE or Huber loss**. \n",
    "- **To minimize the impact of outliers, you will want to use the MAE or Huber loss**.\n",
    "![2.2.1](./figures/2.2.1.PNG)\n",
    "\n",
    "## 4. Defining a loss function\n",
    "- Let's say we decide to use the MSE loss. \n",
    "- We'll need two tensors to compute it: the actual values or \"targets\" tensor and the predicted values or \"predictions.\"\n",
    "- Passing them to the MSE operation will return a single number: the average of the squared differences between the actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2e3442-356d-4353-9984-bdf0f16e2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow under standard alias\n",
    "import tensorflow as tf\n",
    "\n",
    "# compute the MSE loss\n",
    "# loss = tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865b3d9-0cbe-47c7-8508-e2da07a63f5f",
   "metadata": {},
   "source": [
    "### 5. Defining a loss function\n",
    "- In many cases, the training process will require us to supply a function that accepts our model's variables and data and returns a loss. \n",
    "- Here, we'll first define a model, \"linear_regression,\" which takes the intercept, slope, and features as arguments and returns the model's predictions. \n",
    "- We'll next define a loss function called \"loss_function\" that accepts the slope and intercept of a linear model -- the variables -- and the input data, the targets and the features. \n",
    "- It then makes a prediction and computes and returns the associated MSE loss. \n",
    "- Note that we've defined both functions to use default argument values for features and targets. \n",
    "- We will do this whenever we train on the full sample to simplify the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c8da78b-bc0d-43d0-8b69-a6c38057204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a linear regression model\n",
    "# def linear_regression(intercept, slope = slope, features = features):\n",
    "#     return intercept + features*slope\n",
    "\n",
    "# define a loss function to compute the MSE\n",
    "# def loss_funstion(intercept, slope, targets = targets, features = features):\n",
    "#     # compute the predictions for a linear model\n",
    "#     predictions = linear_regression(intercept, slope)\n",
    "    \n",
    "#     # Return the loss\n",
    "#     return tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1beb95-caa8-4067-8d77-a0cbc9b733a0",
   "metadata": {},
   "source": [
    "### 6. Defining the loss function\n",
    "Notice that we've nested TensorFlow's MSE loss function within a function that first uses the model to make predictions and then uses those predictions as an input to the MSE loss function. We can then evaluate this function for a given set of parameter values and input data. Here, we've evaluated the loss function using a test dataset and it returned a loss value of ten point seven seven. If we had omitted the data arguments, test_targets and test_features, the loss function would have instead used the default targets and features arguments we set to evaluate model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b08c6-20ef-45c5-a5db-a581898dd7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f11a2-f468-40cd-be82-f128893ad417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
